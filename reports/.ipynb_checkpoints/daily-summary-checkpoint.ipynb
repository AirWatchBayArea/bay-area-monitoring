{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import deque, OrderedDict\n",
    "from datetime import timedelta, datetime, date, time\n",
    "import os, pytz, calendar, urllib2, json, re, requests, pprint\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    all_data\n",
    "    all_data_summaries\n",
    "except NameError:\n",
    "    all_data = {}\n",
    "    all_data_summaries = {}\n",
    "\n",
    "#chemical names and associated health threshold\n",
    "healthlimits = OrderedDict([(\"Benzene\",          1), \n",
    "                            (\"Black_Carbon\",     5), \n",
    "                            (\"Ethylbenzene\",    60), \n",
    "                            (\"Hydrogen_Sulfide\", 8),\n",
    "                            (\"Sulfur_Dioxide\",  75),\n",
    "                            (\"Toluene\",         70),\n",
    "                            (\"Xylene\",          50)])\n",
    "\n",
    "#investigation time frame\n",
    "#April 2017\n",
    "startDay = datetime(2017,7,1)\n",
    "duration = 30 #days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#returns start and end timestamps of provided start date and duration in number of days\n",
    "def getEpochTimeBounds(d, duration):\n",
    "    dt = assignPacificTimeZone(datetime(d.year,d.month,d.day))\n",
    "    start = calendar.timegm(dt.utctimetuple())\n",
    "    end = calendar.timegm((dt + timedelta(days=duration)).utctimetuple())\n",
    "    return {'start' : start, 'end': end}\n",
    "\n",
    "#attach DST aware timezone offset\n",
    "#Note: does not convert time\n",
    "def assignPacificTimeZone(dt):\n",
    "    pacific = pytz.timezone(\"US/Pacific\")\n",
    "    dt = pacific.localize(dt)\n",
    "    return dt\n",
    "\n",
    "#convert either a unix timestamp or a datetime with tzinfo to a datetime in Pacific time\n",
    "def convertToPacific(time):\n",
    "    if not isinstance(time,datetime):\n",
    "        time = datetime.fromtimestamp(time,tz=pytz.utc)\n",
    "    pacific = pytz.timezone(\"US/Pacific\")\n",
    "    inPacific = time.astimezone(pacific)\n",
    "    return inPacific\n",
    "\n",
    "#returns a date range generator to be used to capture specific days:\n",
    "# Ex:\n",
    "#for single_date in daterange(startDay, duration):\n",
    "#    print single_date.strftime(\"%Y-%m-%d\")\n",
    "def daterange(start_date, duration):\n",
    "    for n in range(duration):\n",
    "        yield start_date + timedelta(n)\n",
    "        \n",
    "#generator for 24 hour times\n",
    "#Ex:\n",
    "#for single_hour in twentyfourhourrange():\n",
    "#     print single_hour.strftime(\"%H:%M:%S\")\n",
    "def twentyfourhourrange():\n",
    "    for n in range(24):\n",
    "        yield (datetime.combine(date.today(), time(0)) + timedelta(hours=(1*n))).time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fenceline ESDR data helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#converts a fenceline feed name to a location\n",
    "def parsefeedcommunity(feedname):\n",
    "    return str(feedname.split('fenceline_org')[0].strip().split('Fence')[0].strip())\n",
    "\n",
    "#returns if an ESDR chemical name relates to a chemical name\n",
    "def parsechemicalname(esdrchemicalname, chemicalname):\n",
    "    return esdrchemicalname.find(chemicalname) > -1\n",
    "\n",
    "#returns a copy of the interested data columns using chemical_map (generated below)\n",
    "def getchemicaldata(monitor, chemical, fenceline_data, chemical_map):\n",
    "    col_names = chemical_map[monitor][chemical]\n",
    "    return fenceline_data[monitor][col_names].copy().replace(\"[^0-9]+\",0,regex=True)\n",
    "\n",
    "#Ex: getchemicaldata('Point Richmond Refinery',\"Hydrogen_Sulfide\",fenceline_data, chemicalmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESDR Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#returns ESDR data as a json\n",
    "def makeESDRrequest(urlsuffix):\n",
    "    url = \"https://esdr.cmucreatelab.org/api/v1/feeds/%s\" % urlsuffix\n",
    "    return json.loads(urllib2.urlopen(url).read())['data']\n",
    "\n",
    "#returns the feed information for a given feedID\n",
    "def loadfeed(feedID):\n",
    "    return makeESDRrequest(feedID)\n",
    "\n",
    "#returns all of the channels for a given feed data (use with loadfeed)\n",
    "def getchannels(feedData):\n",
    "    return [str(channel) for channel in feedData['channelBounds']['channels'].keys()]\n",
    "\n",
    "#returns info on all of the fenceline feeds\n",
    "def getfencelinefeedinfo():\n",
    "    return makeESDRrequest('?fields=id,name,latitude,longitude&whereOr=productId=36&orderBy=+id')['rows']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#feedID: integer\n",
    "#esdrChannels: a list of channel names as strings\n",
    "#timeOptions: a dictionary as {bounds: {start: epochInt, end: epochInt}}, or {day: datetime, duration: int}\n",
    "def makedataframefromESDR(feedID, \n",
    "                          timeOptions = {}):\n",
    "    if timeOptions.get('bounds') == None:\n",
    "        bounds = getEpochTimeBounds(\n",
    "            timeOptions.get('day') or datetime.now()-timedelta(1), \n",
    "            timeOptions.get('duration') or 1)\n",
    "    else:\n",
    "        bounds = timeOptions.get('bounds')\n",
    "        \n",
    "    esdrChannels = getchannels(loadfeed(feedID))\n",
    "    \n",
    "    try:\n",
    "        r = makeESDRrequest(\"%s/channels/%s/export?from=%s&to=%s&format=json\" % (feedID, ','.join(esdrChannels), bounds['start'], bounds['end']))\n",
    "        print \"loaded \" + str(len(r)) + \" data points for feed \" + str(feedID) + \", channels: \" + '|'.join(esdrChannels) + \", time \" + str(bounds['start'])\n",
    "    except:\n",
    "        print \"error loading data from ESDR: feed \" + str(feedID) + \", channel \" + '|'.join(esdrChannels) + \", time \" + str(bounds['start'])\n",
    "    cols = ['Time']\n",
    "    cols.extend(esdrChannels)\n",
    "    df = pd.DataFrame(r,columns=cols)\n",
    "    df['Time'] = pd.to_datetime(df['Time'],unit='s').dt.tz_localize('UTC').dt.tz_convert('US/Pacific')\n",
    "    return df.set_index(['Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 25399 data points for feed 4901, channels: FTIR_System_Status|UV_Signal_Strength|FTIR_Ethanol|FTIR_Mercaptan|FTIR_System_Manufacturer|FTIR_Ammonia|UV_Ozone|FTIR_Methane|FTIR_Carbon_Monoxide|UV_Carbon_Disulfide|FTIR_Nitrous_Oxide|TDL_Signal_Strength|FTIR_Carbonyl_Sulfide|UV_Benzene|FTIR_Total_Hydrocarbons|FTIR_1_3_Butadiene|FTIR_Ethylene|TDL_Hydrogen_Sulfide|UV_Xylene|UV_Toluene|UV_Sulfur_Dioxide|UV_System_Status|FTIR_MTBE, time 1498892400\n",
      "loaded 25480 data points for feed 4902, channels: FTIR_System_Status|UV_Signal_Strength|FTIR_Ethanol|FTIR_Mercaptan|FTIR_System_Manufacturer|FTIR_Ammonia|UV_Ozone|FTIR_Methane|FTIR_Carbon_Monoxide|UV_Carbon_Disulfide|FTIR_Nitrous_Oxide|TDL_Signal_Strength|FTIR_Carbonyl_Sulfide|UV_Benzene|FTIR_Total_Hydrocarbons|FTIR_1_3_Butadiene|FTIR_Ethylene|TDL_Hydrogen_Sulfide|UV_Xylene|UV_Toluene|UV_Sulfur_Dioxide|UV_System_Status|FTIR_MTBE, time 1498892400\n",
      "loaded 17172 data points for feed 4903, channels: Wind_Speed_MPH|Wind_Direction|OGD_System_Status|Humidity|OGD_AT_3|OGD_AT_2|OGD_AT_1|Temperature_F|OGD_AT_6|OGD_AT_5|OGD_AT_4|Dew_Point_F, time 1498892400\n",
      "loaded 41653 data points for feed 4909, channels: Benzene|Wind_Speed_MPH|Wind_Direction|Hydrogen_Sulfide|Humidity|Ozone|Xylene|Temperature_F|Carbon_Disulfide|Dew_Point_F|Sulfur_Dioxide|Skies|Toluene, time 1498892400\n",
      "loaded 41653 data points for feed 4910, channels: Wind_Speed_MPH|m_p_Xylene|o_Xylene|N_Hexane|N_Heptane|3_Methylpentane|Skies|2_2_4_Trimethylpentane|Ethylbenzene|1_3_5_Trimethylbenzene|Black_Carbon|Toluene|Wind_Direction|Humidity|Temperature_F|N_Octane|1_2_3_Trimethylbenzene|Benzene|Hydrogen_Sulfide|1_2_4_Trimethylbenzene|PM_2_5|Dew_Point_F|Ammonia, time 1498892400\n",
      "loaded 41653 data points for feed 4911, channels: Benzene|Wind_Speed_MPH|Wind_Direction|Hydrogen_Sulfide|Humidity|Ozone|Xylene|Temperature_F|Carbon_Disulfide|Dew_Point_F|Sulfur_Dioxide|Skies|Toluene, time 1498892400\n",
      "loaded 41653 data points for feed 4912, channels: Wind_Speed_MPH|m_p_Xylene|o_Xylene|N_Hexane|N_Heptane|3_Methylpentane|Skies|2_2_4_Trimethylpentane|Ethylbenzene|1_3_5_Trimethylbenzene|Black_Carbon|Toluene|Wind_Direction|Humidity|Temperature_F|N_Octane|1_2_3_Trimethylbenzene|Benzene|Hydrogen_Sulfide|1_2_4_Trimethylbenzene|PM_2_5|Dew_Point_F|Ammonia, time 1498892400\n",
      "loaded 41653 data points for feed 4913, channels: Benzene|Wind_Speed_MPH|Wind_Direction|Hydrogen_Sulfide|Humidity|Ozone|Xylene|Temperature_F|Carbon_Disulfide|Dew_Point_F|Sulfur_Dioxide|Skies|Toluene, time 1498892400\n",
      "loaded 41653 data points for feed 4914, channels: Wind_Speed_MPH|m_p_Xylene|o_Xylene|N_Hexane|N_Heptane|3_Methylpentane|Skies|2_2_4_Trimethylpentane|Ethylbenzene|1_3_5_Trimethylbenzene|Black_Carbon|Toluene|Wind_Direction|Humidity|Temperature_F|N_Octane|1_2_3_Trimethylbenzene|Benzene|Hydrogen_Sulfide|1_2_4_Trimethylbenzene|PM_2_5|Dew_Point_F|Ammonia, time 1498892400\n"
     ]
    }
   ],
   "source": [
    "#time frame: 1 month of April, 2017\n",
    "timeframe = {'day':startDay, 'duration':duration}\n",
    "\n",
    "#retrieves fenceline feed information (location, name, feed id)\n",
    "fenceline_feeds = getfencelinefeedinfo()\n",
    "\n",
    "try:\n",
    "    fenceline_data = all_data[(startDay, duration)]\n",
    "except KeyError:\n",
    "    #loads all the data from every channel and every fenceline feed, separated by feed\n",
    "    fenceline_data = {str(parsefeedcommunity(feed['name'])):makedataframefromESDR(feed['id'],timeframe) for feed in fenceline_feeds}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Chemical to Column Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fenceline_columns = {monitor: [x for x in fenceline_data[monitor].columns]\n",
    "                     for monitor in fenceline_data}\n",
    "\n",
    "chemicalmap = {monitor: {chemical:[x for x in fenceline_data[monitor].columns if parsechemicalname(x, chemical)] \n",
    "                     for chemical in healthlimits}\n",
    "               for monitor in fenceline_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def countabovehealthlimit(df, chemical):\n",
    "    countsabovehealthlimit = [];\n",
    "    healthlimit = healthlimits[chemical]\n",
    "    for column in df:\n",
    "        countsabovehealthlimit.append(df[df[column] > healthlimit].count(numeric_only=True).tolist()[0])\n",
    "    return countsabovehealthlimit\n",
    "\n",
    "def countpresence(df, chemical):\n",
    "    countspresence = [];\n",
    "    for column in df:\n",
    "        countspresence.append(df[df[column] > 0].count(numeric_only=True).tolist()[0])\n",
    "    return countspresence\n",
    "    \n",
    "def maxHourlyAverage(df, windFeed, channel):\n",
    "    ret = []\n",
    "    halfHourInSecs = 30 * 60\n",
    "    def avg(x, delta):\n",
    "        ser = df.iloc[(df.index >= x - delta) & (df.index <= x + delta), 0]\n",
    "        return ser.mean()\n",
    "    \n",
    "    healthLimit = 1\n",
    "    df['avg'] = pd.Series(data = df.index, index = df.index).apply(lambda x: avg(x,delta=halfHourInSecs))\n",
    "    maxAvg = df.nlargest(1,'avg')\n",
    "    maxAvgValue = maxAvg.avg.iloc[0]\n",
    "    ret.append(\"%.2f\" % maxAvgValue + unit(channel))\n",
    "    \n",
    "    #don't calculate time and wind data if max average was 0 (below detection limit)\n",
    "    if maxAvgValue != 0:\n",
    "        ret.append(generateHealthFactor(maxAvgValue,channel))\n",
    "    \n",
    "        hourStart = convertToPacific(maxAvg.index[0] - halfHourInSecs).strftime('%I:%M')\n",
    "        hourEnd = convertToPacific(maxAvg.index[0] + halfHourInSecs).strftime('%I:%M%p')\n",
    "        ret.append(hourStart + \"-\" + hourEnd)\n",
    "    \n",
    "        #get wind data for hour with highest average\n",
    "        bounds = {'start':maxAvg.index[0] - halfHourInSecs,'end':maxAvg.index[0] + halfHourInSecs}\n",
    "        wind = makeDataFrameFromEsdr(windFeed,\"Wind_Direction,Wind_Speed_MPH\",\"Wind_Direction,Wind_Speed_MPH\",{'bounds':bounds})\n",
    "        \n",
    "        if len(wind) == 0 or wind['Wind_Direction'].mean() == 0:\n",
    "            ret.append(\"No data\")\n",
    "        else:\n",
    "            #break into quadrants and select the prevailing one\n",
    "            quads = [0,90,180,270,360]\n",
    "            quad_names = ['NE','SE','SW','NW']\n",
    "            wind['Compass_Dir'] = pd.cut(wind['Wind_Direction'],quads,labels=quad_names)\n",
    "            direction = wind.groupby('Compass_Dir').sum().nlargest(1,'Wind_Speed_MPH').index[0]\n",
    "            ret.append(direction)\n",
    "    else:\n",
    "        ret.extend(['0.00','0.00','0.00'])\n",
    "    return ret\n",
    "\n",
    "#total time, in hours, that a detection was present of given chemical or aggregated set of chemicals\n",
    "def calcHoursDetected(df, chemical, sampleFrequency = 1):\n",
    "    detected = df.loc[df[chemical] > 0, [chemical]]\n",
    "    return sampleFrequency * len(detected) / float(60)\n",
    "\n",
    "#total time, in hours, that detection was greater than health threshold of given chemical\n",
    "def calcHoursAboveHealthLimit(df, chemical, sampleFrequency = 1):\n",
    "    limit = channels[chemical]\n",
    "    detected = df.loc[df[chemical] > limit, [chemical]]\n",
    "    return sampleFrequency * len(detected) / float(60)\n",
    "\n",
    "def calcDailyMean(df, chemical, nd=0):\n",
    "    if nd == 0:\n",
    "        fullDecimal = df[chemical].mean()\n",
    "    else:\n",
    "        #substitute readings of 0 for the passed-in non-detect value\n",
    "        #(which should represent that chemicals' detection limit)\n",
    "        fullDecimal = df.replace(0.0,nd)[chemical].mean()\n",
    "    return \"%.2f\" % fullDecimal + unit(chemical)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Data Hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 1.78 minutes\n",
      "Num Processed: 1890\n",
      "Time Per Processed: 56.37 ms\n"
     ]
    }
   ],
   "source": [
    "profilerStart = datetime.now();\n",
    "#Retrieves number of \n",
    "daily_data={}\n",
    "numAnalyzed = 0\n",
    "total_daily_data={}\n",
    "for monitor in fenceline_data.keys():\n",
    "    daily_data[monitor]={}\n",
    "    total_daily_data[monitor]={}\n",
    "    for chemical in healthlimits:\n",
    "        daily_data[monitor][chemical]={}\n",
    "        total_daily_data[monitor][chemical]={\n",
    "            'datasamples':0,\n",
    "            'numabovehealthlimit':0,\n",
    "            'numpresent':0\n",
    "        }\n",
    "        df = getchemicaldata(monitor, chemical, fenceline_data, chemicalmap)\n",
    "        for single_date in daterange(startDay, duration):\n",
    "            numAnalyzed += 1;\n",
    "            daily_data[monitor][chemical][single_date]={}\n",
    "            healthdaycount = 0\n",
    "            presencedaycount = 0\n",
    "            one_day_data = df.loc[single_date.strftime(\"%Y-%m-%d\")]\n",
    "            for single_hour in twentyfourhourrange():\n",
    "                next_hour = datetime.combine(date.today(), single_hour) + timedelta(hours=1)                \n",
    "                one_hour_data = one_day_data.between_time(single_hour.strftime(\"%H:%M:%S\"), next_hour.strftime(\"%H:%M:%S\"))\n",
    "                healthdaycount += 1 if sum(countabovehealthlimit(one_hour_data, chemical)) else 0\n",
    "                presencedaycount += 1 if sum(countpresence(one_hour_data, chemical)) else 0\n",
    "                total_daily_data[monitor][chemical]['datasamples']+=len(one_hour_data)\n",
    "            daily_data[monitor][chemical][single_date]['hoursabovehealthlimit']=healthdaycount\n",
    "            daily_data[monitor][chemical][single_date]['hourspresent']=presencedaycount\n",
    "            total_daily_data[monitor][chemical]['numabovehealthlimit']+=healthdaycount\n",
    "            total_daily_data[monitor][chemical]['numpresent']+=presencedaycount\n",
    "elapsedTime = (datetime.now() - profilerStart).total_seconds()\n",
    "timeperprocessed = elapsedTime/numAnalyzed\n",
    "print \"Elapsed Time: %.2f minutes\" % (elapsedTime/60)\n",
    "print \"Num Processed: %d\" % numAnalyzed\n",
    "print \"Time Per Processed:\", \"%.2f ms\" % (timeperprocessed*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summaries Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateSecondsInAir(totals_data):\n",
    "    sample_rate = (duration*24*60*60) / totals_data['datasamples']\n",
    "    return {\n",
    "        'abovehealthlimit':totals_data['numabovehealthlimit']*sample_rate,\n",
    "        'present': totals_data['numpresent']*sample_rate,\n",
    "    }\n",
    "\n",
    "def formathms(seconds):\n",
    "    m, s = divmod(seconds, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    return \"\".join(['%d hours ' % h if h else \"\", '%d minutes ' % m if m else \"\", '%d seconds' % s if s else \"\"])\n",
    "\n",
    "def calculatePercentageOfTime(totals_data):\n",
    "    return {\n",
    "        'abovehealthlimit':totals_data['numabovehealthlimit']/float(totals_data['datasamples'])*100,\n",
    "        'present': totals_data['numpresent']/float(totals_data['datasamples'])*100,\n",
    "    }\n",
    "\n",
    "def printTimeSummary(time_data, chemical):\n",
    "    if time_data['present'] or time_data['abovehealthlimit']:\n",
    "        print \"\\n   %s:\" % chemical\n",
    "        if time_data['present']:\n",
    "            print '     - was present in the air for at least %s' % formathms(time_data['present'])\n",
    "        elif time_data['abovehealthlimit']:\n",
    "            print '     - was above the health limit for at least %s' % formathms(time_data['abovehealthlimit'])\n",
    "        else:\n",
    "            print \"     - no chemicals detected\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For Rodeo North Monitor for 30 days after 07/01/17\n",
      "\n",
      "   Benzene:\n",
      "     - was present in the air for at least 15 minutes 9 seconds\n",
      "\n",
      "   Xylene:\n",
      "     - was present in the air for at least 16 minutes 50 seconds\n",
      "\n",
      "   Sulfur_Dioxide:\n",
      "     - was present in the air for at least 28 minutes 37 seconds\n",
      "\n",
      "For Point Richmond Refinery Monitor for 30 days after 07/01/17\n",
      "\n",
      "   Hydrogen_Sulfide:\n",
      "     - was present in the air for at least 2 minutes 2 seconds\n",
      "\n",
      "   Sulfur_Dioxide:\n",
      "     - was present in the air for at least 3 minutes 3 seconds\n",
      "\n",
      "For Atchison Village Community Monitor for 30 days after 07/01/17\n",
      "\n",
      "   Benzene:\n",
      "     - was present in the air for at least 3 minutes 3 seconds\n",
      "\n",
      "   Ethylbenzene:\n",
      "     - was present in the air for at least 2 minutes 2 seconds\n",
      "\n",
      "   Black_Carbon:\n",
      "     - was present in the air for at least 11 hours 56 minutes 45 seconds\n",
      "\n",
      "   Hydrogen_Sulfide:\n",
      "     - was present in the air for at least 12 hours 12 minutes \n",
      "\n",
      "   Xylene:\n",
      "     - was present in the air for at least 15 minutes 15 seconds\n",
      "\n",
      "   Toluene:\n",
      "     - was present in the air for at least 1 hours 13 minutes 12 seconds\n",
      "\n",
      "For Rodeo South Monitor for 30 days after 07/01/17\n",
      "\n",
      "   Sulfur_Dioxide:\n",
      "     - was present in the air for at least 3 minutes 24 seconds\n",
      "\n",
      "For Rodeo Monitor for 30 days after 07/01/17\n",
      "\n",
      "For North Richmond Community Monitor for 30 days after 07/01/17\n",
      "\n",
      "   Benzene:\n",
      "     - was present in the air for at least 2 minutes 2 seconds\n",
      "\n",
      "   Ethylbenzene:\n",
      "     - was present in the air for at least 2 minutes 2 seconds\n",
      "\n",
      "   Black_Carbon:\n",
      "     - was present in the air for at least 12 hours 12 minutes \n",
      "\n",
      "   Hydrogen_Sulfide:\n",
      "     - was present in the air for at least 2 hours 33 minutes 31 seconds\n",
      "\n",
      "   Xylene:\n",
      "     - was present in the air for at least 9 hours 26 minutes 17 seconds\n",
      "\n",
      "   Toluene:\n",
      "     - was present in the air for at least 53 minutes 53 seconds\n",
      "\n",
      "For North Richmond Refinery Monitor for 30 days after 07/01/17\n",
      "\n",
      "   Sulfur_Dioxide:\n",
      "     - was present in the air for at least 3 hours 4 minutes 1 seconds\n",
      "\n",
      "For Atchison Village Refinery Monitor for 30 days after 07/01/17\n",
      "\n",
      "   Sulfur_Dioxide:\n",
      "     - was present in the air for at least 9 minutes 9 seconds\n",
      "\n",
      "For Point Richmond Community Monitor for 30 days after 07/01/17\n",
      "\n",
      "   Benzene:\n",
      "     - was present in the air for at least 2 minutes 2 seconds\n",
      "\n",
      "   Ethylbenzene:\n",
      "     - was present in the air for at least 6 minutes 6 seconds\n",
      "\n",
      "   Black_Carbon:\n",
      "     - was present in the air for at least 12 hours 1 minutes 50 seconds\n",
      "\n",
      "   Hydrogen_Sulfide:\n",
      "     - was present in the air for at least 1 hours 19 minutes 18 seconds\n",
      "\n",
      "   Xylene:\n",
      "     - was present in the air for at least 5 minutes 5 seconds\n",
      "\n",
      "   Toluene:\n",
      "     - was present in the air for at least 5 minutes 5 seconds\n"
     ]
    }
   ],
   "source": [
    "data_summary = {}\n",
    "for monitor in total_daily_data:\n",
    "    print \"\\nFor %s Monitor for %d days after %s\" % (monitor, duration, startDay.strftime('%D'))\n",
    "    monitor_data = total_daily_data[monitor]\n",
    "    data_summary[monitor]={}\n",
    "    for chemical in monitor_data:\n",
    "        time_data = calculateTimeInAir(monitor_data[chemical])\n",
    "        percentage_data = calculatePercentageOfTime(monitor_data[chemical])\n",
    "        printTimeSummary(time_data, chemical)\n",
    "        data_summary[monitor][chemical]={'seconds': time_data, 'percent': percentage_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache Data for Future Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data[(startDay, duration)]=fenceline_data\n",
    "all_data_summaries[(startDay, duration)]={\n",
    "    'daily_data':daily_data,\n",
    "    'total_daily_data':total_daily_data,\n",
    "    'data_summary':data_summary,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
