{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os,datetime, pytz, calendar, urllib2, json, re, requests\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#returns start and end timestamps of provided start date and duration in number of days\n",
    "def getEpochTimeBounds(d, duration):\n",
    "    dt = assignPacificTimeZone(datetime.datetime(d.year,d.month,d.day))\n",
    "    start = calendar.timegm(dt.utctimetuple())\n",
    "    end = calendar.timegm((dt + datetime.timedelta(days=duration)).utctimetuple())\n",
    "    return {'start' : start, 'end': end}\n",
    "\n",
    "#attach DST aware timezone offset\n",
    "#Note: does not convert time\n",
    "def assignPacificTimeZone(dt):\n",
    "    pacific = pytz.timezone(\"US/Pacific\")\n",
    "    dt = pacific.localize(dt)\n",
    "    return dt\n",
    "\n",
    "#convert either a unix timestamp or a datetime with tzinfo to a datetime in Pacific time\n",
    "def convertToPacific(time):\n",
    "    if not isinstance(time,datetime.datetime):\n",
    "        time = datetime.datetime.fromtimestamp(time,tz=pytz.utc)\n",
    "    pacific = pytz.timezone(\"US/Pacific\")\n",
    "    inPacific = time.astimezone(pacific)\n",
    "    return inPacific\n",
    "\n",
    "def fillDatum(inputArr,hole):\n",
    "    data = inputArr.popleft()\n",
    "    if not (re.match('0.00+',data) or re.search('\\s0x',data) or re.match('nan',data)):\n",
    "        hole.string = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESDR Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#returns ESDR data as a json\n",
    "def makeESDRrequest(urlsuffix):\n",
    "    url = \"https://esdr.cmucreatelab.org/api/v1/feeds/%s\" % urlsuffix\n",
    "    return json.loads(urllib2.urlopen(url).read())['data']\n",
    "\n",
    "#returns the feed information for a given feedID\n",
    "def loadfeed(feedID):\n",
    "    return makeESDRrequest(feedID)\n",
    "\n",
    "#returns all of the channels for a given feed data (use with loadfeed)\n",
    "def getchannels(feedData):\n",
    "    return [str(channel) for channel in feedData['channelBounds']['channels'].keys()]\n",
    "\n",
    "#returns info on all of the fenceline feeds\n",
    "def getfencelinefeedinfo():\n",
    "    return makeESDRrequest('?fields=id,name,latitude,longitude&whereOr=productId=36&orderBy=+id')['rows']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#feedID: integer\n",
    "#esdrChannels: a list of channel names as strings\n",
    "#timeOptions: a dictionary as {bounds: {start: epochInt, end: epochInt}}, or {day: datetime, duration: int}\n",
    "def makedataframefromESDR(feedID, \n",
    "                          timeOptions = {}):\n",
    "    if timeOptions.get('bounds') == None:\n",
    "        bounds = getEpochTimeBounds(\n",
    "            timeOptions.get('day') or datetime.datetime.now()-datetime.timedelta(1), \n",
    "            timeOptions.get('duration') or 1)\n",
    "    else:\n",
    "        bounds = timeOptions.get('bounds')\n",
    "    esdrChannels = getchannels(loadfeed(feedID))\n",
    "    try:\n",
    "        \n",
    "        makeESDRrequest(\"%s/channels/%s/export?from=%s&to=%s&format=json\" % (feedID, ','.join(esdrChannels), bounds['start'], bounds['end'])\")\n",
    "        print \"loaded \" + str(len(r)) + \" data points for feed \" + str(feedID) + \", channels: \" + '|'.join(esdrChannels) + \", time \" + str(bounds['start'])\n",
    "    except:\n",
    "        print \"error loading data from ESDR: feed \" + str(feedID) + \", channel \" + '|'.join(esdrChannels) + \", time \" + str(bounds['start'])\n",
    "    cols = ['Time']\n",
    "    cols.extend(esdrChannels)\n",
    "    return pd.DataFrame(r,columns=cols).set_index(['Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 25287 data points for feed 4901, channels: FTIR_System_Status|UV_Signal_Strength|FTIR_Ethanol|FTIR_Mercaptan|FTIR_System_Manufacturer|FTIR_Ammonia|UV_Ozone|FTIR_Methane|FTIR_Carbon_Monoxide|UV_Carbon_Disulfide|FTIR_Nitrous_Oxide|TDL_Signal_Strength|FTIR_Carbonyl_Sulfide|UV_Benzene|FTIR_Total_Hydrocarbons|FTIR_1_3_Butadiene|FTIR_Ethylene|TDL_Hydrogen_Sulfide|UV_Xylene|UV_Toluene|UV_Sulfur_Dioxide|UV_System_Status|FTIR_MTBE, time 1491030000\n",
      "loaded 24448 data points for feed 4902, channels: FTIR_System_Status|UV_Signal_Strength|FTIR_Ethanol|FTIR_Mercaptan|FTIR_System_Manufacturer|FTIR_Ammonia|UV_Ozone|FTIR_Methane|FTIR_Carbon_Monoxide|UV_Carbon_Disulfide|FTIR_Nitrous_Oxide|TDL_Signal_Strength|FTIR_Carbonyl_Sulfide|UV_Benzene|FTIR_Total_Hydrocarbons|FTIR_1_3_Butadiene|FTIR_Ethylene|TDL_Hydrogen_Sulfide|UV_Xylene|UV_Toluene|UV_Sulfur_Dioxide|UV_System_Status|FTIR_MTBE, time 1491030000\n",
      "loaded 16910 data points for feed 4903, channels: Wind_Speed_MPH|Wind_Direction|OGD_System_Status|Humidity|OGD_AT_3|OGD_AT_2|OGD_AT_1|Temperature_F|OGD_AT_6|OGD_AT_5|OGD_AT_4|Dew_Point_F, time 1491030000\n",
      "loaded 41914 data points for feed 4909, channels: Benzene|Wind_Speed_MPH|Wind_Direction|Hydrogen_Sulfide|Humidity|Ozone|Xylene|Temperature_F|Carbon_Disulfide|Dew_Point_F|Sulfur_Dioxide|Skies|Toluene, time 1491030000\n",
      "loaded 41914 data points for feed 4910, channels: Wind_Speed_MPH|m_p_Xylene|o_Xylene|N_Hexane|N_Heptane|3_Methylpentane|Skies|2_2_4_Trimethylpentane|Ethylbenzene|1_3_5_Trimethylbenzene|Black_Carbon|Toluene|Wind_Direction|Humidity|Temperature_F|N_Octane|1_2_3_Trimethylbenzene|Benzene|Hydrogen_Sulfide|1_2_4_Trimethylbenzene|PM_2_5|Dew_Point_F|Ammonia, time 1491030000\n",
      "loaded 41914 data points for feed 4911, channels: Benzene|Wind_Speed_MPH|Wind_Direction|Hydrogen_Sulfide|Humidity|Ozone|Xylene|Temperature_F|Carbon_Disulfide|Dew_Point_F|Sulfur_Dioxide|Skies|Toluene, time 1491030000\n",
      "loaded 41914 data points for feed 4912, channels: Wind_Speed_MPH|m_p_Xylene|o_Xylene|N_Hexane|N_Heptane|3_Methylpentane|Skies|2_2_4_Trimethylpentane|Ethylbenzene|1_3_5_Trimethylbenzene|Black_Carbon|Toluene|Wind_Direction|Humidity|Temperature_F|N_Octane|1_2_3_Trimethylbenzene|Benzene|Hydrogen_Sulfide|1_2_4_Trimethylbenzene|PM_2_5|Dew_Point_F|Ammonia, time 1491030000\n",
      "loaded 41914 data points for feed 4913, channels: Benzene|Wind_Speed_MPH|Wind_Direction|Hydrogen_Sulfide|Humidity|Ozone|Xylene|Temperature_F|Carbon_Disulfide|Dew_Point_F|Sulfur_Dioxide|Skies|Toluene, time 1491030000\n",
      "loaded 41914 data points for feed 4914, channels: Wind_Speed_MPH|m_p_Xylene|o_Xylene|N_Hexane|N_Heptane|3_Methylpentane|Skies|2_2_4_Trimethylpentane|Ethylbenzene|1_3_5_Trimethylbenzene|Black_Carbon|Toluene|Wind_Direction|Humidity|Temperature_F|N_Octane|1_2_3_Trimethylbenzene|Benzene|Hydrogen_Sulfide|1_2_4_Trimethylbenzene|PM_2_5|Dew_Point_F|Ammonia, time 1491030000\n"
     ]
    }
   ],
   "source": [
    "#time frame: 1 month of April, 2017\n",
    "interestedtimeframe = {'day':datetime.datetime(2017,4,1), 'duration':30}\n",
    "\n",
    "#retrieves fenceline feed information (location, name, feed id)\n",
    "fenceline_feeds = getfencelinefeedinfo()\n",
    "\n",
    "#loads all the data from every channel and every fenceline feed, separated by feed\n",
    "fenceline_data = {str(feed['name']):makedataframefromESDR(feed['id'],interestedtimeframe) for feed in fenceline_feeds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Atchison Village Community fenceline_org',\n",
       " 'Atchison Village Refinery Fence Line fenceline_org',\n",
       " 'North Richmond Community fenceline_org',\n",
       " 'Rodeo fenceline_org',\n",
       " 'Point Richmond Community fenceline_org',\n",
       " 'North Richmond Refinery Fence Line fenceline_org',\n",
       " 'Rodeo South Fenceline fenceline_org',\n",
       " 'Point Richmond Refinery Fence Line fenceline_org',\n",
       " 'Rodeo North Fenceline fenceline_org']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
