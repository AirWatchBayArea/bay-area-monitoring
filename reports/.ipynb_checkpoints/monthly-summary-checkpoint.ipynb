{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import deque, OrderedDict\n",
    "from datetime import timedelta, datetime, date, time\n",
    "import os, pytz, calendar, urllib2, json, re, requests, pprint\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#chemical names and associated health threshold\n",
    "healthlimits = OrderedDict([(\"Benzene\",          1), \n",
    "                            (\"Black_Carbon\",     5), \n",
    "                            (\"Ethylbenzene\",    60), \n",
    "                            (\"Hydrogen_Sulfide\", 8),\n",
    "                            (\"Sulfur_Dioxide\",  75),\n",
    "                            (\"Toluene\",         70),\n",
    "                            (\"Xylene\",          50)])\n",
    "\n",
    "#investigation time frame\n",
    "#April 2017\n",
    "startDay = datetime(2017,4,1)\n",
    "duration = 30 #days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#returns start and end timestamps of provided start date and duration in number of days\n",
    "def getEpochTimeBounds(d, duration):\n",
    "    dt = assignPacificTimeZone(datetime(d.year,d.month,d.day))\n",
    "    start = calendar.timegm(dt.utctimetuple())\n",
    "    end = calendar.timegm((dt + timedelta(days=duration)).utctimetuple())\n",
    "    return {'start' : start, 'end': end}\n",
    "\n",
    "#attach DST aware timezone offset\n",
    "#Note: does not convert time\n",
    "def assignPacificTimeZone(dt):\n",
    "    pacific = pytz.timezone(\"US/Pacific\")\n",
    "    dt = pacific.localize(dt)\n",
    "    return dt\n",
    "\n",
    "#convert either a unix timestamp or a datetime with tzinfo to a datetime in Pacific time\n",
    "def convertToPacific(time):\n",
    "    if not isinstance(time,datetime):\n",
    "        time = datetime.fromtimestamp(time,tz=pytz.utc)\n",
    "    pacific = pytz.timezone(\"US/Pacific\")\n",
    "    inPacific = time.astimezone(pacific)\n",
    "    return inPacific\n",
    "\n",
    "#returns a date range generator to be used to capture specific days:\n",
    "# Ex:\n",
    "#for single_date in daterange(startDay, duration):\n",
    "#    print single_date.strftime(\"%Y-%m-%d\")\n",
    "def daterange(start_date, duration):\n",
    "    for n in range(duration):\n",
    "        yield start_date + timedelta(n)\n",
    "        \n",
    "#generator for 24 hour times\n",
    "#Ex:\n",
    "#for single_hour in twentyfourhourrange():\n",
    "#     print single_hour.strftime(\"%H:%M:%S\")\n",
    "def twentyfourhourrange():\n",
    "    for n in range(24):\n",
    "        yield (datetime.combine(date.today(), time(0)) + timedelta(hours=(1*n))).time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fenceline ESDR data helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#converts a fenceline feed name to a location\n",
    "def parsefeedcommunity(feedname):\n",
    "    return str(feedname.split('fenceline_org')[0].strip().split('Fence')[0].strip())\n",
    "\n",
    "#returns if an ESDR chemical name relates to a chemical name\n",
    "def parsechemicalname(esdrchemicalname, chemicalname):\n",
    "    return esdrchemicalname.find(chemicalname) > -1\n",
    "\n",
    "#returns a copy of the interested data columns using chemical_map (generated below)\n",
    "def getchemicaldata(monitor, chemical, fenceline_data, chemical_map):\n",
    "    col_names = chemical_map[monitor][chemical]\n",
    "    return fenceline_data[monitor][col_names].copy().replace(\"[^0-9]+\",0,regex=True)\n",
    "\n",
    "#Ex: getchemicaldata('Point Richmond Refinery',\"Hydrogen_Sulfide\",fenceline_data, chemicalmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESDR Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#returns ESDR data as a json\n",
    "def makeESDRrequest(urlsuffix):\n",
    "    url = \"https://esdr.cmucreatelab.org/api/v1/feeds/%s\" % urlsuffix\n",
    "    return json.loads(urllib2.urlopen(url).read())['data']\n",
    "\n",
    "#returns the feed information for a given feedID\n",
    "def loadfeed(feedID):\n",
    "    return makeESDRrequest(feedID)\n",
    "\n",
    "#returns all of the channels for a given feed data (use with loadfeed)\n",
    "def getchannels(feedData):\n",
    "    return [str(channel) for channel in feedData['channelBounds']['channels'].keys()]\n",
    "\n",
    "#returns info on all of the fenceline feeds\n",
    "def getfencelinefeedinfo():\n",
    "    return makeESDRrequest('?fields=id,name,latitude,longitude&whereOr=productId=36&orderBy=+id')['rows']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#feedID: integer\n",
    "#esdrChannels: a list of channel names as strings\n",
    "#timeOptions: a dictionary as {bounds: {start: epochInt, end: epochInt}}, or {day: datetime, duration: int}\n",
    "def makedataframefromESDR(feedID, \n",
    "                          timeOptions = {}):\n",
    "    if timeOptions.get('bounds') == None:\n",
    "        bounds = getEpochTimeBounds(\n",
    "            timeOptions.get('day') or datetime.now()-timedelta(1), \n",
    "            timeOptions.get('duration') or 1)\n",
    "    else:\n",
    "        bounds = timeOptions.get('bounds')\n",
    "        \n",
    "    esdrChannels = getchannels(loadfeed(feedID))\n",
    "    \n",
    "    try:\n",
    "        r = makeESDRrequest(\"%s/channels/%s/export?from=%s&to=%s&format=json\" % (feedID, ','.join(esdrChannels), bounds['start'], bounds['end']))\n",
    "        print \"loaded \" + str(len(r)) + \" data points for feed \" + str(feedID) + \", channels: \" + '|'.join(esdrChannels) + \", time \" + str(bounds['start'])\n",
    "    except:\n",
    "        print \"error loading data from ESDR: feed \" + str(feedID) + \", channel \" + '|'.join(esdrChannels) + \", time \" + str(bounds['start'])\n",
    "    cols = ['Time']\n",
    "    cols.extend(esdrChannels)\n",
    "    df = pd.DataFrame(r,columns=cols)\n",
    "    df['Time'] = pd.to_datetime(df['Time'],unit='s').dt.tz_localize('UTC').dt.tz_convert('US/Pacific')\n",
    "    return df.set_index(['Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 25287 data points for feed 4901, channels: FTIR_System_Status|UV_Signal_Strength|FTIR_Ethanol|FTIR_Mercaptan|FTIR_System_Manufacturer|FTIR_Ammonia|UV_Ozone|FTIR_Methane|FTIR_Carbon_Monoxide|UV_Carbon_Disulfide|FTIR_Nitrous_Oxide|TDL_Signal_Strength|FTIR_Carbonyl_Sulfide|UV_Benzene|FTIR_Total_Hydrocarbons|FTIR_1_3_Butadiene|FTIR_Ethylene|TDL_Hydrogen_Sulfide|UV_Xylene|UV_Toluene|UV_Sulfur_Dioxide|UV_System_Status|FTIR_MTBE, time 1491030000\n",
      "loaded 24448 data points for feed 4902, channels: FTIR_System_Status|UV_Signal_Strength|FTIR_Ethanol|FTIR_Mercaptan|FTIR_System_Manufacturer|FTIR_Ammonia|UV_Ozone|FTIR_Methane|FTIR_Carbon_Monoxide|UV_Carbon_Disulfide|FTIR_Nitrous_Oxide|TDL_Signal_Strength|FTIR_Carbonyl_Sulfide|UV_Benzene|FTIR_Total_Hydrocarbons|FTIR_1_3_Butadiene|FTIR_Ethylene|TDL_Hydrogen_Sulfide|UV_Xylene|UV_Toluene|UV_Sulfur_Dioxide|UV_System_Status|FTIR_MTBE, time 1491030000\n",
      "loaded 16910 data points for feed 4903, channels: Wind_Speed_MPH|Wind_Direction|OGD_System_Status|Humidity|OGD_AT_3|OGD_AT_2|OGD_AT_1|Temperature_F|OGD_AT_6|OGD_AT_5|OGD_AT_4|Dew_Point_F, time 1491030000\n",
      "loaded 41914 data points for feed 4909, channels: Benzene|Wind_Speed_MPH|Wind_Direction|Hydrogen_Sulfide|Humidity|Ozone|Xylene|Temperature_F|Carbon_Disulfide|Dew_Point_F|Sulfur_Dioxide|Skies|Toluene, time 1491030000\n",
      "loaded 41914 data points for feed 4910, channels: Wind_Speed_MPH|m_p_Xylene|o_Xylene|N_Hexane|N_Heptane|3_Methylpentane|Skies|2_2_4_Trimethylpentane|Ethylbenzene|1_3_5_Trimethylbenzene|Black_Carbon|Toluene|Wind_Direction|Humidity|Temperature_F|N_Octane|1_2_3_Trimethylbenzene|Benzene|Hydrogen_Sulfide|1_2_4_Trimethylbenzene|PM_2_5|Dew_Point_F|Ammonia, time 1491030000\n",
      "loaded 41914 data points for feed 4911, channels: Benzene|Wind_Speed_MPH|Wind_Direction|Hydrogen_Sulfide|Humidity|Ozone|Xylene|Temperature_F|Carbon_Disulfide|Dew_Point_F|Sulfur_Dioxide|Skies|Toluene, time 1491030000\n",
      "loaded 41914 data points for feed 4912, channels: Wind_Speed_MPH|m_p_Xylene|o_Xylene|N_Hexane|N_Heptane|3_Methylpentane|Skies|2_2_4_Trimethylpentane|Ethylbenzene|1_3_5_Trimethylbenzene|Black_Carbon|Toluene|Wind_Direction|Humidity|Temperature_F|N_Octane|1_2_3_Trimethylbenzene|Benzene|Hydrogen_Sulfide|1_2_4_Trimethylbenzene|PM_2_5|Dew_Point_F|Ammonia, time 1491030000\n",
      "loaded 41914 data points for feed 4913, channels: Benzene|Wind_Speed_MPH|Wind_Direction|Hydrogen_Sulfide|Humidity|Ozone|Xylene|Temperature_F|Carbon_Disulfide|Dew_Point_F|Sulfur_Dioxide|Skies|Toluene, time 1491030000\n",
      "loaded 41914 data points for feed 4914, channels: Wind_Speed_MPH|m_p_Xylene|o_Xylene|N_Hexane|N_Heptane|3_Methylpentane|Skies|2_2_4_Trimethylpentane|Ethylbenzene|1_3_5_Trimethylbenzene|Black_Carbon|Toluene|Wind_Direction|Humidity|Temperature_F|N_Octane|1_2_3_Trimethylbenzene|Benzene|Hydrogen_Sulfide|1_2_4_Trimethylbenzene|PM_2_5|Dew_Point_F|Ammonia, time 1491030000\n"
     ]
    }
   ],
   "source": [
    "#time frame: 1 month of April, 2017\n",
    "timeframe = {'day':startDay, 'duration':duration}\n",
    "\n",
    "#retrieves fenceline feed information (location, name, feed id)\n",
    "fenceline_feeds = getfencelinefeedinfo()\n",
    "\n",
    "#loads all the data from every channel and every fenceline feed, separated by feed\n",
    "fenceline_data = {str(parsefeedcommunity(feed['name'])):makedataframefromESDR(feed['id'],timeframe) for feed in fenceline_feeds}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Chemical to Column Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fenceline_columns = {monitor: [x for x in fenceline_data[monitor].columns]\n",
    "                     for monitor in fenceline_data}\n",
    "\n",
    "chemicalmap = {monitor: {chemical:[x for x in fenceline_data[monitor].columns if parsechemicalname(x, chemical)] \n",
    "                     for chemical in healthlimits}\n",
    "               for monitor in fenceline_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def countabovehealthlimit(df, chemical):\n",
    "    countsabovehealthlimit = [];\n",
    "    healthlimit = healthlimits[chemical]\n",
    "    for column in df:\n",
    "        countsabovehealthlimit.append(df[df[column] > healthlimit].count(numeric_only=True).tolist()[0])\n",
    "    return countsabovehealthlimit\n",
    "\n",
    "def countpresence(df, chemical):\n",
    "    countspresence = [];\n",
    "    for column in df:\n",
    "        countspresence.append(df[df[column] > 0].count(numeric_only=True).tolist()[0])\n",
    "    return countspresence\n",
    "\n",
    "def maxHourlyAverage(df, windFeed, channel):\n",
    "    ret = []\n",
    "    halfHourInSecs = 30 * 60\n",
    "    def avg(x, delta):\n",
    "        ser = df.iloc[(df.index >= x - delta) & (df.index <= x + delta), 0]\n",
    "        return ser.mean()\n",
    "    \n",
    "    healthLimit = 1\n",
    "    df['avg'] = pd.Series(data = df.index, index = df.index).apply(lambda x: avg(x,delta=halfHourInSecs))\n",
    "    maxAvg = df.nlargest(1,'avg')\n",
    "    maxAvgValue = maxAvg.avg.iloc[0]\n",
    "    ret.append(\"%.2f\" % maxAvgValue + unit(channel))\n",
    "    \n",
    "    #don't calculate time and wind data if max average was 0 (below detection limit)\n",
    "    if maxAvgValue != 0:\n",
    "        ret.append(generateHealthFactor(maxAvgValue,channel))\n",
    "    \n",
    "        hourStart = convertToPacific(maxAvg.index[0] - halfHourInSecs).strftime('%I:%M')\n",
    "        hourEnd = convertToPacific(maxAvg.index[0] + halfHourInSecs).strftime('%I:%M%p')\n",
    "        ret.append(hourStart + \"-\" + hourEnd)\n",
    "    \n",
    "        #get wind data for hour with highest average\n",
    "        bounds = {'start':maxAvg.index[0] - halfHourInSecs,'end':maxAvg.index[0] + halfHourInSecs}\n",
    "        wind = makeDataFrameFromEsdr(windFeed,\"Wind_Direction,Wind_Speed_MPH\",\"Wind_Direction,Wind_Speed_MPH\",{'bounds':bounds})\n",
    "        \n",
    "        if len(wind) == 0 or wind['Wind_Direction'].mean() == 0:\n",
    "            ret.append(\"No data\")\n",
    "        else:\n",
    "            #break into quadrants and select the prevailing one\n",
    "            quads = [0,90,180,270,360]\n",
    "            quad_names = ['NE','SE','SW','NW']\n",
    "            wind['Compass_Dir'] = pd.cut(wind['Wind_Direction'],quads,labels=quad_names)\n",
    "            direction = wind.groupby('Compass_Dir').sum().nlargest(1,'Wind_Speed_MPH').index[0]\n",
    "            ret.append(direction)\n",
    "    else:\n",
    "        ret.extend(['0.00','0.00','0.00'])\n",
    "    return ret\n",
    "\n",
    "#total time, in hours, that a detection was present of given chemical or aggregated set of chemicals\n",
    "def calcHoursDetected(df, chemical, sampleFrequency = 1):\n",
    "    detected = df.loc[df[chemical] > 0, [chemical]]\n",
    "    fullDecimal = sampleFrequency * len(detected) / float(60)\n",
    "    return \"%.2f\" % fullDecimal + \" hours\"\n",
    "\n",
    "#total time, in hours, that detection was greater than health threshold of given chemical\n",
    "def calcHoursAboveHealthLimit(df, chemical, sampleFrequency = 1):\n",
    "    limit = channels[chemical]\n",
    "    detected = df.loc[df[chemical] > limit, [chemical]]\n",
    "    fullDecimal = sampleFrequency * len(detected) / float(60)\n",
    "    return \"%.2f\" % fullDecimal + \" hours\"\n",
    "#calcHoursAboveHealthLimit(df, \"Benzene\")\n",
    "\n",
    "def calcDailyMean(df, chemical, nd=0):\n",
    "    if nd == 0:\n",
    "        fullDecimal = df[chemical].mean()\n",
    "    else:\n",
    "        #substitute readings of 0 for the passed-in non-detect value\n",
    "        #(which should represent that chemicals' detection limit)\n",
    "        fullDecimal = df.replace(0.0,nd)[chemical].mean()\n",
    "    return \"%.2f\" % fullDecimal + unit(chemical)\n",
    "#calcDailyMean(df,\"Benzene\", 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Data Hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "profilerStart = datetime.now();\n",
    "#Retrieves number of \n",
    "daily_data={}\n",
    "numAnalyzed = 0;\n",
    "for monitor in fenceline_data.keys():\n",
    "    daily_data[monitor]={};\n",
    "    for chemical in healthlimits:\n",
    "        daily_data[monitor][chemical]={}\n",
    "        df = getchemicaldata(monitor, chemical, fenceline_data, chemicalmap)\n",
    "        for single_date in daterange(startDay, duration):\n",
    "            numAnalyzed += 1;\n",
    "            daily_data[monitor][chemical][single_date]={}\n",
    "            healthdaycount = 0\n",
    "            presencedaycount = 0\n",
    "            one_day_data = df[single_date.strftime(\"%Y-%m-%d\")]\n",
    "            for single_hour in twentyfourhourrange():\n",
    "                next_hour = datetime.combine(date.today(), single_hour) + timedelta(hours=1)                \n",
    "                one_hour_data = one_day_data.between_time(single_hour.strftime(\"%H:%M:%S\"), next_hour.strftime(\"%H:%M:%S\"))\n",
    "                healthdaycount += 1 if sum(countabovehealthlimit(one_hour_data, chemical)) else 0\n",
    "                presencedaycount += 1 if sum(countpresence(one_hour_data, chemical)) else 0\n",
    "            daily_data[monitor][chemical][single_date]['hoursabovehealthlimit']=healthdaycount\n",
    "            daily_data[monitor][chemical][single_date]['hourspresent']=presencedaycount\n",
    "elapsedTime = (datetime.now() - profilerStart).totalseconds()\n",
    "timeperprocessed = elapsedTime/numAnalyzed\n",
    "print \"Elapsed Time:\", elapsedTime, \"seconds\"\n",
    "print \"Time Per Hour Processed:\", timeperprocessed, \"seconds\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{datetime.datetime(2017, 4, 1, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 3},\n",
       " datetime.datetime(2017, 4, 2, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 1},\n",
       " datetime.datetime(2017, 4, 3, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 4},\n",
       " datetime.datetime(2017, 4, 4, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 2},\n",
       " datetime.datetime(2017, 4, 5, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 0},\n",
       " datetime.datetime(2017, 4, 6, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 0},\n",
       " datetime.datetime(2017, 4, 7, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 0},\n",
       " datetime.datetime(2017, 4, 8, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 0},\n",
       " datetime.datetime(2017, 4, 9, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 0},\n",
       " datetime.datetime(2017, 4, 10, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 0},\n",
       " datetime.datetime(2017, 4, 11, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 2},\n",
       " datetime.datetime(2017, 4, 12, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 2},\n",
       " datetime.datetime(2017, 4, 13, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 2},\n",
       " datetime.datetime(2017, 4, 14, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 1},\n",
       " datetime.datetime(2017, 4, 15, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 2},\n",
       " datetime.datetime(2017, 4, 16, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 10},\n",
       " datetime.datetime(2017, 4, 17, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 3},\n",
       " datetime.datetime(2017, 4, 18, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 13},\n",
       " datetime.datetime(2017, 4, 19, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 16},\n",
       " datetime.datetime(2017, 4, 20, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 11},\n",
       " datetime.datetime(2017, 4, 21, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 14},\n",
       " datetime.datetime(2017, 4, 22, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 12},\n",
       " datetime.datetime(2017, 4, 23, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 13},\n",
       " datetime.datetime(2017, 4, 24, 0, 0): {'hoursabovehealthlimit': 1,\n",
       "  'hourspresent': 17},\n",
       " datetime.datetime(2017, 4, 25, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 18},\n",
       " datetime.datetime(2017, 4, 26, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 19},\n",
       " datetime.datetime(2017, 4, 27, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 15},\n",
       " datetime.datetime(2017, 4, 28, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 18},\n",
       " datetime.datetime(2017, 4, 29, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 20},\n",
       " datetime.datetime(2017, 4, 30, 0, 0): {'hoursabovehealthlimit': 0,\n",
       "  'hourspresent': 21}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_data['North Richmond Community']['Hydrogen_Sulfide']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "getchemicaldata('Point Richmond Refinery',\"Hydrogen_Sulfide\",fenceline_data, chemicalmap)['2017-04-01':'2017-04-02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(-1, 86399, 999989)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
