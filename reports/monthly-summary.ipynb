{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import deque, OrderedDict\n",
    "from datetime import timedelta, datetime, date, time\n",
    "import os, pytz, calendar, urllib2, json, re, requests, pprint\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#chemical names and associated health threshold\n",
    "healthlimits = OrderedDict([(\"Benzene\",          1), \n",
    "                            (\"Black_Carbon\",     5), \n",
    "                            (\"Ethylbenzene\",    60), \n",
    "                            (\"Hydrogen_Sulfide\", 8),\n",
    "                            (\"Sulfur_Dioxide\",  75),\n",
    "                            (\"Toluene\",         70),\n",
    "                            (\"Xylene\",          50)])\n",
    "\n",
    "#investigation time frame\n",
    "#April 2017\n",
    "startDay = datetime(2017,4,1)\n",
    "duration = 30 #days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#returns start and end timestamps of provided start date and duration in number of days\n",
    "def getEpochTimeBounds(d, duration):\n",
    "    dt = assignPacificTimeZone(datetime(d.year,d.month,d.day))\n",
    "    start = calendar.timegm(dt.utctimetuple())\n",
    "    end = calendar.timegm((dt + timedelta(days=duration)).utctimetuple())\n",
    "    return {'start' : start, 'end': end}\n",
    "\n",
    "#attach DST aware timezone offset\n",
    "#Note: does not convert time\n",
    "def assignPacificTimeZone(dt):\n",
    "    pacific = pytz.timezone(\"US/Pacific\")\n",
    "    dt = pacific.localize(dt)\n",
    "    return dt\n",
    "\n",
    "#convert either a unix timestamp or a datetime with tzinfo to a datetime in Pacific time\n",
    "def convertToPacific(time):\n",
    "    if not isinstance(time,datetime):\n",
    "        time = datetime.fromtimestamp(time,tz=pytz.utc)\n",
    "    pacific = pytz.timezone(\"US/Pacific\")\n",
    "    inPacific = time.astimezone(pacific)\n",
    "    return inPacific\n",
    "\n",
    "#returns a date range generator to be used to capture specific days:\n",
    "# Ex:\n",
    "#for single_date in daterange(startDay, duration):\n",
    "#    print single_date.strftime(\"%Y-%m-%d\")\n",
    "def daterange(start_date, duration):\n",
    "    for n in range(duration):\n",
    "        yield start_date + timedelta(n)\n",
    "        \n",
    "#generator for 24 hour times\n",
    "#Ex:\n",
    "#for single_hour in twentyfourhourrange():\n",
    "#     print single_hour.strftime(\"%H:%M:%S\")\n",
    "def twentyfourhourrange():\n",
    "    for n in range(24):\n",
    "        yield (datetime.combine(date.today(), time(0)) + timedelta(hours=(1*n))).time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fenceline ESDR data helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#converts a fenceline feed name to a location\n",
    "def parsefeedcommunity(feedname):\n",
    "    return str(feedname.split('fenceline_org')[0].strip().split('Fence')[0].strip())\n",
    "\n",
    "#returns if an ESDR chemical name relates to a chemical name\n",
    "def parsechemicalname(esdrchemicalname, chemicalname):\n",
    "    return esdrchemicalname.find(chemicalname) > -1\n",
    "\n",
    "#returns a copy of the interested data columns using chemical_map (generated below)\n",
    "def getchemicaldata(monitor, chemical, fenceline_data, chemical_map):\n",
    "    col_names = chemical_map[monitor][chemical]\n",
    "    return fenceline_data[monitor][col_names].copy().replace(\"[^0-9]+\",0,regex=True)\n",
    "\n",
    "#Ex: getchemicaldata('Point Richmond Refinery',\"Hydrogen_Sulfide\",fenceline_data, chemicalmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESDR Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#returns ESDR data as a json\n",
    "def makeESDRrequest(urlsuffix):\n",
    "    url = \"https://esdr.cmucreatelab.org/api/v1/feeds/%s\" % urlsuffix\n",
    "    return json.loads(urllib2.urlopen(url).read())['data']\n",
    "\n",
    "#returns the feed information for a given feedID\n",
    "def loadfeed(feedID):\n",
    "    return makeESDRrequest(feedID)\n",
    "\n",
    "#returns all of the channels for a given feed data (use with loadfeed)\n",
    "def getchannels(feedData):\n",
    "    return [str(channel) for channel in feedData['channelBounds']['channels'].keys()]\n",
    "\n",
    "#returns info on all of the fenceline feeds\n",
    "def getfencelinefeedinfo():\n",
    "    return makeESDRrequest('?fields=id,name,latitude,longitude&whereOr=productId=36&orderBy=+id')['rows']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#feedID: integer\n",
    "#esdrChannels: a list of channel names as strings\n",
    "#timeOptions: a dictionary as {bounds: {start: epochInt, end: epochInt}}, or {day: datetime, duration: int}\n",
    "def makedataframefromESDR(feedID, \n",
    "                          timeOptions = {}):\n",
    "    if timeOptions.get('bounds') == None:\n",
    "        bounds = getEpochTimeBounds(\n",
    "            timeOptions.get('day') or datetime.now()-timedelta(1), \n",
    "            timeOptions.get('duration') or 1)\n",
    "    else:\n",
    "        bounds = timeOptions.get('bounds')\n",
    "        \n",
    "    esdrChannels = getchannels(loadfeed(feedID))\n",
    "    \n",
    "    try:\n",
    "        r = makeESDRrequest(\"%s/channels/%s/export?from=%s&to=%s&format=json\" % (feedID, ','.join(esdrChannels), bounds['start'], bounds['end']))\n",
    "        print \"loaded \" + str(len(r)) + \" data points for feed \" + str(feedID) + \", channels: \" + '|'.join(esdrChannels) + \", time \" + str(bounds['start'])\n",
    "    except:\n",
    "        print \"error loading data from ESDR: feed \" + str(feedID) + \", channel \" + '|'.join(esdrChannels) + \", time \" + str(bounds['start'])\n",
    "    cols = ['Time']\n",
    "    cols.extend(esdrChannels)\n",
    "    df = pd.DataFrame(r,columns=cols)\n",
    "    df['Time'] = pd.to_datetime(df['Time'],unit='s').dt.tz_localize('UTC').dt.tz_convert('US/Pacific')\n",
    "    return df.set_index(['Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 25287 data points for feed 4901, channels: FTIR_System_Status|UV_Signal_Strength|FTIR_Ethanol|FTIR_Mercaptan|FTIR_System_Manufacturer|FTIR_Ammonia|UV_Ozone|FTIR_Methane|FTIR_Carbon_Monoxide|UV_Carbon_Disulfide|FTIR_Nitrous_Oxide|TDL_Signal_Strength|FTIR_Carbonyl_Sulfide|UV_Benzene|FTIR_Total_Hydrocarbons|FTIR_1_3_Butadiene|FTIR_Ethylene|TDL_Hydrogen_Sulfide|UV_Xylene|UV_Toluene|UV_Sulfur_Dioxide|UV_System_Status|FTIR_MTBE, time 1491030000\n",
      "loaded 24448 data points for feed 4902, channels: FTIR_System_Status|UV_Signal_Strength|FTIR_Ethanol|FTIR_Mercaptan|FTIR_System_Manufacturer|FTIR_Ammonia|UV_Ozone|FTIR_Methane|FTIR_Carbon_Monoxide|UV_Carbon_Disulfide|FTIR_Nitrous_Oxide|TDL_Signal_Strength|FTIR_Carbonyl_Sulfide|UV_Benzene|FTIR_Total_Hydrocarbons|FTIR_1_3_Butadiene|FTIR_Ethylene|TDL_Hydrogen_Sulfide|UV_Xylene|UV_Toluene|UV_Sulfur_Dioxide|UV_System_Status|FTIR_MTBE, time 1491030000\n",
      "loaded 16910 data points for feed 4903, channels: Wind_Speed_MPH|Wind_Direction|OGD_System_Status|Humidity|OGD_AT_3|OGD_AT_2|OGD_AT_1|Temperature_F|OGD_AT_6|OGD_AT_5|OGD_AT_4|Dew_Point_F, time 1491030000\n",
      "loaded 41914 data points for feed 4909, channels: Benzene|Wind_Speed_MPH|Wind_Direction|Hydrogen_Sulfide|Humidity|Ozone|Xylene|Temperature_F|Carbon_Disulfide|Dew_Point_F|Sulfur_Dioxide|Skies|Toluene, time 1491030000\n",
      "loaded 41914 data points for feed 4910, channels: Wind_Speed_MPH|m_p_Xylene|o_Xylene|N_Hexane|N_Heptane|3_Methylpentane|Skies|2_2_4_Trimethylpentane|Ethylbenzene|1_3_5_Trimethylbenzene|Black_Carbon|Toluene|Wind_Direction|Humidity|Temperature_F|N_Octane|1_2_3_Trimethylbenzene|Benzene|Hydrogen_Sulfide|1_2_4_Trimethylbenzene|PM_2_5|Dew_Point_F|Ammonia, time 1491030000\n",
      "loaded 41914 data points for feed 4911, channels: Benzene|Wind_Speed_MPH|Wind_Direction|Hydrogen_Sulfide|Humidity|Ozone|Xylene|Temperature_F|Carbon_Disulfide|Dew_Point_F|Sulfur_Dioxide|Skies|Toluene, time 1491030000\n",
      "loaded 41914 data points for feed 4912, channels: Wind_Speed_MPH|m_p_Xylene|o_Xylene|N_Hexane|N_Heptane|3_Methylpentane|Skies|2_2_4_Trimethylpentane|Ethylbenzene|1_3_5_Trimethylbenzene|Black_Carbon|Toluene|Wind_Direction|Humidity|Temperature_F|N_Octane|1_2_3_Trimethylbenzene|Benzene|Hydrogen_Sulfide|1_2_4_Trimethylbenzene|PM_2_5|Dew_Point_F|Ammonia, time 1491030000\n",
      "loaded 41914 data points for feed 4913, channels: Benzene|Wind_Speed_MPH|Wind_Direction|Hydrogen_Sulfide|Humidity|Ozone|Xylene|Temperature_F|Carbon_Disulfide|Dew_Point_F|Sulfur_Dioxide|Skies|Toluene, time 1491030000\n",
      "loaded 41914 data points for feed 4914, channels: Wind_Speed_MPH|m_p_Xylene|o_Xylene|N_Hexane|N_Heptane|3_Methylpentane|Skies|2_2_4_Trimethylpentane|Ethylbenzene|1_3_5_Trimethylbenzene|Black_Carbon|Toluene|Wind_Direction|Humidity|Temperature_F|N_Octane|1_2_3_Trimethylbenzene|Benzene|Hydrogen_Sulfide|1_2_4_Trimethylbenzene|PM_2_5|Dew_Point_F|Ammonia, time 1491030000\n"
     ]
    }
   ],
   "source": [
    "#time frame: 1 month of April, 2017\n",
    "timeframe = {'day':startDay, 'duration':duration}\n",
    "\n",
    "#retrieves fenceline feed information (location, name, feed id)\n",
    "fenceline_feeds = getfencelinefeedinfo()\n",
    "\n",
    "#loads all the data from every channel and every fenceline feed, separated by feed\n",
    "fenceline_data = {str(parsefeedcommunity(feed['name'])):makedataframefromESDR(feed['id'],timeframe) for feed in fenceline_feeds}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Chemical to Column Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fenceline_columns = {monitor: [x for x in fenceline_data[monitor].columns]\n",
    "                     for monitor in fenceline_data}\n",
    "\n",
    "chemicalmap = {monitor: {chemical:[x for x in fenceline_data[monitor].columns if parsechemicalname(x, chemical)] \n",
    "                     for chemical in healthlimits}\n",
    "               for monitor in fenceline_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def countabovehealthlimit(df, chemical):\n",
    "    countsabovehealthlimit = [];\n",
    "    healthlimit = healthlimits[chemical]\n",
    "    for column in df:\n",
    "        countsabovehealthlimit.append(df[df[column] > healthlimit].count(numeric_only=True).tolist()[0])\n",
    "    return countsabovehealthlimit\n",
    "\n",
    "def countpresence(df, chemical):\n",
    "    countspresence = [];\n",
    "    for column in df:\n",
    "        countspresence.append(df[df[column] > 0].count(numeric_only=True).tolist()[0])\n",
    "    return countspresence\n",
    "    \n",
    "def maxHourlyAverage(df, windFeed, channel):\n",
    "    ret = []\n",
    "    halfHourInSecs = 30 * 60\n",
    "    def avg(x, delta):\n",
    "        ser = df.iloc[(df.index >= x - delta) & (df.index <= x + delta), 0]\n",
    "        return ser.mean()\n",
    "    \n",
    "    healthLimit = 1\n",
    "    df['avg'] = pd.Series(data = df.index, index = df.index).apply(lambda x: avg(x,delta=halfHourInSecs))\n",
    "    maxAvg = df.nlargest(1,'avg')\n",
    "    maxAvgValue = maxAvg.avg.iloc[0]\n",
    "    ret.append(\"%.2f\" % maxAvgValue + unit(channel))\n",
    "    \n",
    "    #don't calculate time and wind data if max average was 0 (below detection limit)\n",
    "    if maxAvgValue != 0:\n",
    "        ret.append(generateHealthFactor(maxAvgValue,channel))\n",
    "    \n",
    "        hourStart = convertToPacific(maxAvg.index[0] - halfHourInSecs).strftime('%I:%M')\n",
    "        hourEnd = convertToPacific(maxAvg.index[0] + halfHourInSecs).strftime('%I:%M%p')\n",
    "        ret.append(hourStart + \"-\" + hourEnd)\n",
    "    \n",
    "        #get wind data for hour with highest average\n",
    "        bounds = {'start':maxAvg.index[0] - halfHourInSecs,'end':maxAvg.index[0] + halfHourInSecs}\n",
    "        wind = makeDataFrameFromEsdr(windFeed,\"Wind_Direction,Wind_Speed_MPH\",\"Wind_Direction,Wind_Speed_MPH\",{'bounds':bounds})\n",
    "        \n",
    "        if len(wind) == 0 or wind['Wind_Direction'].mean() == 0:\n",
    "            ret.append(\"No data\")\n",
    "        else:\n",
    "            #break into quadrants and select the prevailing one\n",
    "            quads = [0,90,180,270,360]\n",
    "            quad_names = ['NE','SE','SW','NW']\n",
    "            wind['Compass_Dir'] = pd.cut(wind['Wind_Direction'],quads,labels=quad_names)\n",
    "            direction = wind.groupby('Compass_Dir').sum().nlargest(1,'Wind_Speed_MPH').index[0]\n",
    "            ret.append(direction)\n",
    "    else:\n",
    "        ret.extend(['0.00','0.00','0.00'])\n",
    "    return ret\n",
    "\n",
    "#total time, in hours, that a detection was present of given chemical or aggregated set of chemicals\n",
    "def calcHoursDetected(df, chemical, sampleFrequency = 1):\n",
    "    detected = df.loc[df[chemical] > 0, [chemical]]\n",
    "    return sampleFrequency * len(detected) / float(60)\n",
    "\n",
    "#total time, in hours, that detection was greater than health threshold of given chemical\n",
    "def calcHoursAboveHealthLimit(df, chemical, sampleFrequency = 1):\n",
    "    limit = channels[chemical]\n",
    "    detected = df.loc[df[chemical] > limit, [chemical]]\n",
    "    return sampleFrequency * len(detected) / float(60)\n",
    "\n",
    "def calcDailyMean(df, chemical, nd=0):\n",
    "    if nd == 0:\n",
    "        fullDecimal = df[chemical].mean()\n",
    "    else:\n",
    "        #substitute readings of 0 for the passed-in non-detect value\n",
    "        #(which should represent that chemicals' detection limit)\n",
    "        fullDecimal = df.replace(0.0,nd)[chemical].mean()\n",
    "    return \"%.2f\" % fullDecimal + unit(chemical)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Data Hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-2964e23cc426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0melapsedTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mprofilerStart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mtimeperprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melapsedTime\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnumAnalyzed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Elapsed Time: %.2f minutes\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0melapsedTime\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Num Processed: %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnumAnalyzed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Time Per Processed:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%.2f ms\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtimeperprocessed\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "profilerStart = datetime.now();\n",
    "#Retrieves number of \n",
    "daily_data={}\n",
    "numAnalyzed = 0\n",
    "total_daily_data={}\n",
    "for monitor in fenceline_data.keys():\n",
    "    daily_data[monitor]={}\n",
    "    total_daily_data[monitor]={}\n",
    "    for chemical in healthlimits:\n",
    "        daily_data[monitor][chemical]={}\n",
    "        total_daily_data[monitor][chemical]={\n",
    "            'datasamples':0,\n",
    "            'numabovehealthlimit':0,\n",
    "            'numpresent':0\n",
    "        }\n",
    "        df = getchemicaldata(monitor, chemical, fenceline_data, chemicalmap)\n",
    "        for single_date in daterange(startDay, duration):\n",
    "            numAnalyzed += 1;\n",
    "            daily_data[monitor][chemical][single_date]={}\n",
    "            healthdaycount = 0\n",
    "            presencedaycount = 0\n",
    "            one_day_data = df.loc[single_date.strftime(\"%Y-%m-%d\")]\n",
    "            for single_hour in twentyfourhourrange():\n",
    "                next_hour = datetime.combine(date.today(), single_hour) + timedelta(hours=1)                \n",
    "                one_hour_data = one_day_data.between_time(single_hour.strftime(\"%H:%M:%S\"), next_hour.strftime(\"%H:%M:%S\"))\n",
    "                healthdaycount += 1 if sum(countabovehealthlimit(one_hour_data, chemical)) else 0\n",
    "                presencedaycount += 1 if sum(countpresence(one_hour_data, chemical)) else 0\n",
    "                total_daily_data[monitor][chemical]['datasamples']+=len(one_hour_data)\n",
    "            daily_data[monitor][chemical][single_date]['hoursabovehealthlimit']=healthdaycount\n",
    "            daily_data[monitor][chemical][single_date]['hourspresent']=presencedaycount\n",
    "            total_daily_data[monitor][chemical]['numabovehealthlimit']+=healthdaycount\n",
    "            total_daily_data[monitor][chemical]['numpresent']+=presencedaycount\n",
    "elapsedTime = (datetime.now() - profilerStart).total_seconds()\n",
    "timeperprocessed = elapsedTime/numAnalyzed\n",
    "print \"Elapsed Time: %.2f minutes\" % (elapsedTime/60)\n",
    "print \"Num Processed: %d\" % numAnalyzed\n",
    "print \"Time Per Processed:\", \"%.2f ms\" % (timeperprocessed*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Rodeo North Monitor for 30 days after Saturday, April 6\n",
      "\n",
      "   Benzene:\n",
      "     - was present in the air for at least 2 hours 47 minutes 50 seconds\n",
      "     - was above the health limit for at least 2 hours 47 minutes 50 seconds\n",
      "\n",
      "   Sulfur_Dioxide:\n",
      "     - was present in the air for at least 3 hours 47 minutes 54 seconds\n",
      "\n",
      "   Toluene:\n",
      "     - was present in the air for at least 14 minutes 8 seconds\n",
      "\n",
      "For Point Richmond Refinery Monitor for 30 days after Saturday, April 6\n",
      "\n",
      "   Hydrogen_Sulfide:\n",
      "     - was present in the air for at least 17 minutes \n",
      "     - was above the health limit for at least 17 minutes \n",
      "\n",
      "   Xylene:\n",
      "     - was present in the air for at least 3 minutes \n",
      "\n",
      "   Sulfur_Dioxide:\n",
      "     - was present in the air for at least 1 hours 31 minutes \n",
      "\n",
      "For Atchison Village Community Monitor for 30 days after Saturday, April 6\n",
      "\n",
      "   Benzene:\n",
      "     - was present in the air for at least 13 minutes \n",
      "     - was above the health limit for at least 4 minutes \n",
      "\n",
      "   Ethylbenzene:\n",
      "     - was present in the air for at least 7 minutes \n",
      "\n",
      "   Black_Carbon:\n",
      "     - was present in the air for at least 11 hours 56 minutes \n",
      "\n",
      "   Hydrogen_Sulfide:\n",
      "     - was present in the air for at least 12 hours \n",
      "\n",
      "   Xylene:\n",
      "     - was present in the air for at least 33 minutes \n",
      "\n",
      "   Toluene:\n",
      "     - was present in the air for at least 1 hours 36 minutes \n",
      "\n",
      "For Rodeo South Monitor for 30 days after Saturday, April 6\n",
      "\n",
      "   Sulfur_Dioxide:\n",
      "     - was present in the air for at least 22 minutes 6 seconds\n",
      "\n",
      "For Rodeo Monitor for 30 days after Saturday, April 6\n",
      "\n",
      "For North Richmond Community Monitor for 30 days after Saturday, April 6\n",
      "\n",
      "   Benzene:\n",
      "     - was present in the air for at least 8 minutes \n",
      "     - was above the health limit for at least 2 minutes \n",
      "\n",
      "   Black_Carbon:\n",
      "     - was present in the air for at least 11 hours 44 minutes \n",
      "     - was above the health limit for at least 15 minutes \n",
      "\n",
      "   Hydrogen_Sulfide:\n",
      "     - was present in the air for at least 3 hours 59 minutes \n",
      "     - was above the health limit for at least 1 minutes \n",
      "\n",
      "   Xylene:\n",
      "     - was present in the air for at least 9 minutes \n",
      "\n",
      "   Toluene:\n",
      "     - was present in the air for at least 1 hours 8 minutes \n",
      "\n",
      "For North Richmond Refinery Monitor for 30 days after Saturday, April 6\n",
      "\n",
      "   Xylene:\n",
      "     - was present in the air for at least 7 minutes \n",
      "\n",
      "   Sulfur_Dioxide:\n",
      "     - was present in the air for at least 2 hours 41 minutes \n",
      "\n",
      "For Atchison Village Refinery Monitor for 30 days after Saturday, April 6\n",
      "\n",
      "   Sulfur_Dioxide:\n",
      "     - was present in the air for at least 49 minutes \n",
      "\n",
      "   Toluene:\n",
      "     - was present in the air for at least 9 minutes \n",
      "\n",
      "For Point Richmond Community Monitor for 30 days after Saturday, April 6\n",
      "\n",
      "   Benzene:\n",
      "     - was present in the air for at least 1 minutes \n",
      "\n",
      "   Black_Carbon:\n",
      "     - was present in the air for at least 10 hours 35 minutes \n",
      "     - was above the health limit for at least 1 minutes \n",
      "\n",
      "   Hydrogen_Sulfide:\n",
      "     - was present in the air for at least 1 hours 5 minutes \n",
      "\n",
      "   Xylene:\n",
      "     - was present in the air for at least 17 minutes \n",
      "     - was above the health limit for at least 2 minutes \n",
      "\n",
      "   Toluene:\n",
      "     - was present in the air for at least 21 minutes \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for monitor in total_daily_data:\n",
    "    print \"For %s Monitor for %d days after %s\" % (monitor, duration, startDay.strftime('%A, %B %w'))\n",
    "    monitor_data = total_daily_data[monitor]\n",
    "    for chemical in monitor_data:\n",
    "        time_data = calculateTimeInAir(monitor_data[chemical])\n",
    "        if time_data['present'] or time_data['abovehealthlimit']:\n",
    "            print \"\\n   %s:\" % chemical\n",
    "            if time_data['present']:\n",
    "                print '     - was present in the air for at least %s' % formathms(time_data['present'])\n",
    "            if time_data['abovehealthlimit']:\n",
    "                print '     - was above the health limit for at least %s' % formathms(time_data['abovehealthlimit'])\n",
    "#         percentage_data = calculatePercentageOfTime(monitor_data[chemical]);\n",
    "#         print chemical, monitor_data[chemical]\n",
    "#         print '%s:\\n- was present in the air %.3f%% of samples\\n- was above the health limit %.3f%% of the time' % (chemical, percentage_data['present'], percentage_data['abovehealthlimit'])\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# getchemicaldata('Point Richmond Refinery',\"Hydrogen_Sulfide\",fenceline_data, chemicalmap)['2017-04-01':'2017-04-02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
